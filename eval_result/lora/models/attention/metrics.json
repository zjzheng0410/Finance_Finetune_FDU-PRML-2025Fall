{
  "model": "LoRA::Qwen/Qwen2.5-7B-Instruct::/workspace/LLaMA-Factory/saves/attention",
  "gen_cfg": {
    "max_new_tokens": 256,
    "do_sample": false,
    "temperature": 0.0,
    "top_p": 1.0,
    "repetition_penalty": 1.0
  },
  "max_input_tokens": 2048,
  "batch_size": 24,
  "finance": {
    "n": 976,
    "exact_match": 0.0,
    "rouge": {
      "rouge1": 0.2571188495239579,
      "rouge2": 0.06283156769549358,
      "rougeL": 0.16665480699881327
    },
    "bleu": {
      "bleu": 3.0534726483291026
    },
    "chrf": {
      "chrf": 22.237893630341933
    },
    "length_pred_words": {
      "mean": 154.39446721311475,
      "p50": 170.0,
      "p90": 235.0
    },
    "length_ref_words": {
      "mean": 168.60245901639345,
      "p50": 123.0,
      "p90": 345.5
    },
    "latency_sec_total": 346.17079973220825,
    "latency_sec_per_sample": 0.3546831964469347,
    "pred_file": "eval_runs/20260112_115330_three/models/attention/pred_finance.jsonl"
  },
  "general": {
    "n": 2470,
    "exact_match": 0.002834008097165992,
    "rouge": {
      "rouge1": 0.3760317469485778,
      "rouge2": 0.18934566574675402,
      "rougeL": 0.29785455784611914
    },
    "bleu": {
      "bleu": 11.494106784564247
    },
    "chrf": {
      "chrf": 39.575421088715984
    },
    "length_pred_words": {
      "mean": 62.9251012145749,
      "p50": 47.0,
      "p90": 127.0
    },
    "length_ref_words": {
      "mean": 41.298785425101215,
      "p50": 26.0,
      "p90": 96.0
    },
    "latency_sec_total": 793.7894644737244,
    "latency_sec_per_sample": 0.3213722528233702,
    "pred_file": "eval_runs/20260112_115330_three/models/attention/pred_general.jsonl"
  }
}